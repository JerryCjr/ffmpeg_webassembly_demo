<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">
    <title>Document</title>
    <style>
        .upload {
            width: 400px;
            height: 400px;
            border: 1px solid red;
            position: fixed;
            left: 0;
            top: 0;
            z-index: 99;
        }
    </style>
</head>



<body>
    <div class="upload">
        <input type="file" id="uploadFile">
    </div>

</body>

<script>
    console.log(1);
    let animationId = null;
    let finish = false;
    window.AudioContext = window.AudioContext || window.webkitAudioContext || window.mozAudioContext || window.msAudioContext;
    const audioContext = new AudioContext();
    const audioFile = document.getElementById('uploadFile');
    audioFile.onchange = function (e) {
        const file = e.target.files[0];
        const fr = new FileReader();
        fr.onload = function (e) {
            console.log(e);
            const fileResult = e.target.result;
            audioContext.decodeAudioData(fileResult, function (buffer) {
                var audioBufferSouceNode = audioContext.createBufferSource(),
                    analyser = audioContext.createAnalyser(),
                    gainNode = audioContext.createGain();
                analyser.fftSize = 64;
                const bufferLength = analyser.frequencyBinCount;
                // const dataArray = new Float32Array(bufferLength);
                const dataArray = new Uint8Array(bufferLength);
                audioBufferSouceNode.connect(gainNode);
                gainNode.connect(analyser);
                analyser.connect(audioContext.destination);
                audioBufferSouceNode.buffer = buffer;
                audioBufferSouceNode.start(0);
                audioBufferSouceNode.onended = function () {
                    console.log('end');
                    if (animationId !== null) {
                        cancelAnimationFrame(animationId);
                    }
                }

                //生成 2D canvas
                const canvas = document.createElement('canvas');
                canvas.style.position = 'absolute';
                canvas.style.top = 0;
                canvas.style.left = 0;
                canvas.width = window.innerWidth;
                canvas.height = window.innerHeight;
                document.body.appendChild(canvas);
                const canvasCtx = canvas.getContext('2d');
                canvasCtx.clearRect(0, 0, canvas.width, canvas.height);


                function draw() {
                    //准备好下次重绘
                    animationId = requestAnimationFrame(draw);

                    //获取实时的频谱信息
                    // analyser.getFloatFrequencyData(dataArray);
                    analyser.getByteFrequencyData(dataArray);

                    //画一个黑色的背景
                    canvasCtx.fillStyle = 'rgb(0, 0, 0)';
                    canvasCtx.fillRect(0, 0, canvas.width, canvas.height);

                    //绘制频谱
                    const barWidth = (canvas.width / bufferLength) * 2.5;
                    let posX = 0;
                    for (let i = 0; i < bufferLength; i++) {
                        // console.log(dataArray[i]);
                        console.log(gainNode);
                        const barHeight = (dataArray[i] + 140) * 2;
                        canvasCtx.fillStyle = 'rgb(' + Math.floor(barHeight + 100) + ', 50, 50)';
                        canvasCtx.fillRect(posX, canvas.height - barHeight / 2, barWidth, barHeight / 2);
                        posX += barWidth + 1;
                        // if (i === bufferLength - 1) {
                        //     if (animationId !== null) {
                        //         cancelAnimationFrame(animationId);
                        //     }
                        // }
                    }
                };

                draw();
            }, function (e) {
                console.error(e);
            });

        }
        fr.readAsArrayBuffer(file);
    }

    // const audioCtx = new AudioContext();

    //创建一个音频源
    //在示例中我们使用了一个音频文件,但其实这里也可以用麦克风输入
    // const audioEle = new Audio();
    // audioEle.src = './audio/DEMO_1.mp3';//这里是文件名
    // audioEle.autoplay = true;
    // audioEle.preload = 'auto';
    // const audioSourceNode = audioCtx.createMediaElementSource(audioEle);

    //生成一个分析节点(analyser node)
    // const analyserNode = audioCtx.createAnalyser();
    // analyserNode.fftSize = 256;
    // const bufferLength = analyserNode.frequencyBinCount;
    // const dataArray = new Float32Array(bufferLength);

    // //设置音频节点网络（音频源->分析节点->输出）
    // audioSourceNode.connect(analyserNode);
    // analyserNode.connect(audioCtx.destination);


</script>

</html>